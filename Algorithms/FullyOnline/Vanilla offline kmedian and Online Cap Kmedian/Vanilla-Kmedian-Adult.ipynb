{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= 'Adult'  #Name of the dataset from ['Adult','Bank']\n",
    "order= 'random'  # Order of data points with respect to protected group - random or arbitrary\n",
    "\n",
    "Ktarget = 10   #Target or desired number of clusters \n",
    "\n",
    "\n",
    "#Point 1. Capture all costs as squared euclidean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90de3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import numba\n",
    "from numba import jit , njit\n",
    "from csv import writer\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "#!pip install scikit-learn-extra\n",
    "from sklearn.cluster import KMeans\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset,Ktarget):\n",
    "    \n",
    "    flag= True\n",
    "    if dataset=='Adult':\n",
    "        _filename = 'adult_p.csv'\n",
    "        OriCenters=[]\n",
    "    elif dataset=='Bank':\n",
    "        _filename = 'bank_p.csv'\n",
    "        OriCenters=[]\n",
    "        \n",
    "    elif dataset=='Synthetic-1d':\n",
    "        \n",
    "        OriCenters=[1]\n",
    "        cluster1 = np.random.normal([1], 2, 1000)\n",
    "        \n",
    "            \n",
    "        df=pd.DataFrame(cluster1, columns=['X'])\n",
    "        for kk in range(1,Ktarget):\n",
    "           \n",
    "            cluster1 = np.random.normal([1+7*kk],2 , 1000)\n",
    "            OriCenters.append([1+7*kk])\n",
    "           \n",
    "          \n",
    "            df1=pd.DataFrame(cluster1, columns=['X'])\n",
    "            df=pd.concat([df,df1])\n",
    "            \n",
    "      \n",
    "        df = df.reset_index()  \n",
    "        \n",
    "        df = df.drop(df.columns[0],axis=1)\n",
    "       \n",
    "        df=shuffleDataset(df)\n",
    "        OriCenters=np.array(OriCenters)\n",
    "        flag= False\n",
    "        \n",
    "        \n",
    "    elif dataset=='Synthetic-2d-over':\n",
    "        \n",
    "\n",
    "        cluster1 = np.random.multivariate_normal([1,3], [[1, 0], [0, 1]], 1000)\n",
    "        OriCenters=[[1,3]]\n",
    "            \n",
    "        df=pd.DataFrame(cluster1, columns=['X','Y'])\n",
    "        for kk in range(1,Ktarget):\n",
    "           \n",
    "            cluster1 = np.random.multivariate_normal([1+5*kk,3], [[1, 0], [0, 1]], 1000)\n",
    "            \n",
    "            OriCenters.append([1+5*kk,3])\n",
    "          \n",
    "            df1=pd.DataFrame(cluster1, columns=['X','Y'])\n",
    "            df=pd.concat([df,df1])\n",
    "            \n",
    "      \n",
    "        df = df.reset_index()\n",
    "        df = df.drop(df.columns[0],axis=1)\n",
    "        #print(df)\n",
    "        \n",
    "        \n",
    "        plot2Ddata(df['X'],df['Y'])\n",
    "        df=shuffleDataset(df)\n",
    "        OriCenters=np.array(OriCenters)\n",
    "        flag= False\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif dataset=='Synthetic-2d': #well separated\n",
    "        \n",
    "\n",
    "        cluster1 = np.random.multivariate_normal([1,3], [[1, 0], [0, 1]], 1000)\n",
    "        OriCenters=[[1,3]]\n",
    "            \n",
    "        df=pd.DataFrame(cluster1, columns=['X','Y'])\n",
    "        for kk in range(1,Ktarget):\n",
    "           \n",
    "            cluster1 = np.random.multivariate_normal([1+7*kk,3], [[1, 0], [0, 1]], 1000)\n",
    "            \n",
    "            OriCenters.append([1+7*kk,3])\n",
    "          \n",
    "            df1=pd.DataFrame(cluster1, columns=['X','Y'])\n",
    "            df=pd.concat([df,df1])\n",
    "            \n",
    "      \n",
    "        df = df.reset_index()\n",
    "        df = df.drop(df.columns[0],axis=1)\n",
    "        #print(df)\n",
    "        \n",
    "        \n",
    "        plot2Ddata(df['X'],df['Y'])\n",
    "        df=shuffleDataset(df)\n",
    "        OriCenters=np.array(OriCenters)\n",
    "        flag= False\n",
    "        \n",
    "    elif dataset=='Synthetic-1d-Over':\n",
    "        \n",
    "        OriCenters=[1]\n",
    "        cluster1 = np.random.normal([1], 2, 1000)\n",
    "        \n",
    "            \n",
    "        df=pd.DataFrame(cluster1, columns=['X'])\n",
    "        for kk in range(1,Ktarget):\n",
    "           \n",
    "            cluster1 = np.random.normal([1+5*kk],2 , 1000)\n",
    "            OriCenters.append([1+5*kk])\n",
    "           \n",
    "          \n",
    "            df1=pd.DataFrame(cluster1, columns=['X'])\n",
    "            df=pd.concat([df,df1])\n",
    "            \n",
    "      \n",
    "        df = df.reset_index()  \n",
    "        \n",
    "        df = df.drop(df.columns[0],axis=1)\n",
    "       \n",
    "        df=shuffleDataset(df)\n",
    "        OriCenters=np.array(OriCenters)\n",
    "        flag= False\n",
    "        \n",
    "    elif dataset=='Synthetic-arb':\n",
    "        flag= False\n",
    "        pass\n",
    "    \n",
    "    if flag:\n",
    "        \n",
    "        df = pd.read_csv(_filename, sep=',')#[:10000]\n",
    "        df= df.round(decimals=5)\n",
    "        df = df.dropna()\n",
    "    \n",
    "        if order=='random':\n",
    "            df=shuffleDataset(df)\n",
    "        \n",
    "    print('Dataset loaded........')\n",
    "    \n",
    "    #df.to_csv('SeededData/'+str(dataset)+'_seed_'+str(seed)+'.csv',index=False)\n",
    "    \n",
    "    return df,OriCenters\n",
    "        \n",
    "def plot2Ddata(x,y):\n",
    "    plt.plot(x, y, 'x')\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92934584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleDataset(df):\n",
    "\n",
    "    df = shuffle(df)\n",
    "    df = shuffle(df)    #random with respect to group and distance\n",
    "    df = shuffle(df)\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns='index')\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9735a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def EuclideanDistance(x,y):\n",
    "    sum_ = 0\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        \n",
    "        sum_ = sum_ + (x[i]-y[i])**2\n",
    "\n",
    "    return sum_#**0.5\n",
    "\n",
    "\n",
    "def EuclideanDistance_(x,y):\n",
    "    sum_ = 0\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "#     print()\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        \n",
    "        sum_ = sum_ + (x[i]-y[i])**2\n",
    "\n",
    "    return sum_#**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def Distances(rows,center): \n",
    "    # Numpy array - center and rows\n",
    "    #Finds the distance of rows to 1 center in fast parallel way\n",
    "    \n",
    "    #need centers in col\n",
    "    rr = len(rows)\n",
    "    cc = len(center) \n",
    "   \n",
    "    dist=np.zeros((rr, cc)) \n",
    "    \n",
    "    \n",
    "    \n",
    "    for indr in range(0,len(rows)):\n",
    "        \n",
    "        \n",
    "        \n",
    "        for indce in range(0,len(center)):\n",
    "            \n",
    "            dis = EuclideanDistance(rows[indr],center[indce])\n",
    "            dist[indr][indce]= dis\n",
    "            \n",
    "    \n",
    "    return dist\n",
    " \n",
    "#@njit(parallel=False)\n",
    "def sortedDistances1(centers,row): \n",
    "    # Numpy array - center and rows\n",
    "    #Finds the distance of rows to 1 center in fast parallel way\n",
    "    \n",
    "    distOfCenters = []\n",
    "    \n",
    "    \n",
    "    for indce in range(0,len(centers)): # each center is tuple of index, center vector \n",
    "        dis = EuclideanDistance_(row,centers[indce][1])\n",
    "        distOfCenters.append(tuple((dis,centers[indce][0])))  #add distance, original center id \n",
    "        \n",
    "            \n",
    "    #sorted_centers = sorted(distToCenters, key=lambda x: x[0])\n",
    "    distOfCenters.sort()  #inPlace sorts \n",
    "    \n",
    "    \n",
    "    return distOfCenters\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34244a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def kmedian(x,k, no_of_iterations):\n",
    "    idx = np.random.choice(len(x), k, replace=False)\n",
    "    #Randomly choosing Centroids\n",
    "    centroids = x[idx, :] #Step 1\n",
    "     \n",
    "    #finding the distance between centroids and all the data points\n",
    "    distances = cdist(x, centroids ,'sqeuclidean') #Step 2\n",
    "     \n",
    "    #Centroid with the minimum Distance\n",
    "    points = np.array([np.argmin(i) for i in distances]) #Step 3\n",
    "     \n",
    "    #Repeating the above steps for a defined number of iterations\n",
    "    #Step 4\n",
    "    for _ in range(no_of_iterations):\n",
    "        centroids = []\n",
    "        for idx in range(k):\n",
    "            #Updating Centroids by taking mean of Cluster it belongs to\n",
    "            assign = x[points==idx]\n",
    "            temp_cent = np.median(assign,axis=0)\n",
    "            centroids.append(temp_cent)\n",
    " \n",
    "        centroids = np.vstack(centroids) #Updated Centroids\n",
    "         \n",
    "        distances = cdist(x, centroids ,'sqeuclidean')\n",
    "        points = np.array([np.argmin(i) for i in distances])\n",
    "   \n",
    "    cost = 0\n",
    "        \n",
    "    for i in range(0,len(distances)):\n",
    "        cost += distances[i][points[i]]\n",
    "            \n",
    "    return points,cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e39eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapHeur(Ktarget,X,capacities):\n",
    "    \n",
    "    n_row, n_col = X.shape\n",
    "    rand_indices = np.random.choice(n_row, size = Ktarget)\n",
    "    maxiter=100\n",
    "  \n",
    "    centroids = X[rand_indices]\n",
    "\n",
    "    \n",
    "   \n",
    "    for itr in range(maxiter):\n",
    "        distances_to_centroids = Distances(X, centroids)#distance.cdist(X, centroids, 'sqeuclidean')\n",
    "        \n",
    "\n",
    "        \n",
    "        cluster_assignment=[]\n",
    "        \n",
    "        capacities_iter= np.array(capacities,dtype=np.int64)#(tuple of form (center idx,capacity))\n",
    "        #Deep copies it into this np.array()\n",
    "        \n",
    "        for idx in range(0,len(X)):\n",
    "            #print(distances_to_centroids[idx])\n",
    "            sorted_centerIDs = np.argsort(distances_to_centroids[idx])\n",
    "            \n",
    "            for idc in sorted_centerIDs:\n",
    "            \n",
    "                if capacities_iter[int(idc)][1] >0:\n",
    "                    cluster_assignment.append(idc)\n",
    "                    capacities_iter[int(idc)][1] -=1\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "        #print(\"Found {} assignements for iteration {}.\".format(len(cluster_assignment), itr))\n",
    "               \n",
    "        cluster_assignment=np.array(cluster_assignment)   \n",
    "        \n",
    "        new_centroids=[]\n",
    "        for i  in range(Ktarget):\n",
    "            \n",
    "            assign= np.array([X[cluster_assignment == i]])\n",
    "            #print('shape of assign is ',assign)\n",
    "            med = np.median(assign,axis=1)\n",
    "            #print('shape of med is ',med)\n",
    "            new_centroids.append(med)\n",
    "            \n",
    "            \n",
    "       \n",
    "            \n",
    "        new_centroids = np.array(new_centroids)\n",
    "        new_centroids = new_centroids.reshape(Ktarget,len(X[0]))\n",
    "        \n",
    "            \n",
    "        if np.all(centroids == new_centroids):\n",
    "                break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "        #print('centroids are ',centroids)\n",
    "            \n",
    "    \n",
    "    \n",
    "    cost = []\n",
    "    for i in range(Ktarget):\n",
    "        cluster_data = X[cluster_assignment == i]\n",
    "        distances = distance.cdist(cluster_data, [centroids[i]], 'euclidean')\n",
    "        cost.append( np.sum(distances ** 2))\n",
    "    \n",
    "    return np.sum(cost)\n",
    "\n",
    "\n",
    "def LowerBoundCapHeuristic(dfValues):\n",
    "    ans_mean=[]\n",
    "    ans_std=[]\n",
    "    KtargetList =[1099,844,1231,1354,1488,292,474,806,1153,3143,4657,5946,7136,9865]\n",
    "    for Ktarget in KtargetList:\n",
    "        print('K is ',Ktarget)\n",
    "        w_list = []\n",
    "        seeds=[0,100,200]#,300,400,500,600,700,800,900]\n",
    "        for seed in seeds:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            capacities=[]\n",
    "\n",
    "            for i in range(Ktarget):\n",
    "                capacities.append([i,np.ceil(len(dfValues)/Ktarget)])  #(centerId,capacity)\n",
    "\n",
    "            w_list.append(CapHeur(Ktarget,dfValues,capacities))\n",
    "\n",
    "        print(np.mean(w_list))\n",
    "        print(np.std(w_list))\n",
    "        print('*'*10)\n",
    "        ans_mean.append(np.mean(w_list))\n",
    "        ans_std.append(np.std(w_list))\n",
    "    return ans_mean,ans_std\n",
    "\n",
    "def CostVanillaKmedian1(dfValues):\n",
    "    \n",
    "    ans_mean=[]\n",
    "    ans_std = []\n",
    "\n",
    "    KtargetList =[1231,1354,1488,292,474,806,1153,3143,4657,5946,7136,9865]\n",
    "    for Ktarget in KtargetList:\n",
    "        print('K is ',Ktarget)\n",
    "        seeds=[0,500]#,300,400,500,600,700,800,900]\n",
    "        cost = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            _,kmean_obj = kmedian(dfValues, Ktarget, 100) #KMeans(n_clusters=Ktarget, init='random' ,random_state=seed).fit(dfValues)\n",
    "\n",
    "            cost.append(kmean_obj)    #Sum of squarred euc dis \n",
    "\n",
    "\n",
    "        print(np.mean(cost))\n",
    "        print(np.std(cost))\n",
    "        print('*'*10)\n",
    "        ans_mean.append(np.mean(cost))\n",
    "        ans_std.append(np.std(cost))\n",
    "        \n",
    "        \n",
    "    return ans_mean,ans_std#, np.std(cost)    #average over 10 runs     \n",
    "\n",
    "\n",
    "\n",
    "df,OriCenters = load_dataset(dataset,10)\n",
    "dfValues = df.values\n",
    "\n",
    "df,OriCenters = load_dataset(dataset,10)\n",
    "dfValues = df.values\n",
    "ans_mean,ans_std=CostVanillaKmedian1(dfValues)\n",
    "\n",
    "print(ans_mean)\n",
    "print(ans_std)\n",
    "print()\n",
    "\n",
    "\n",
    "ans_mean,ans_std=LowerBoundCapHeuristic(dfValues)\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(ans_mean)\n",
    "print(ans_std)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e648d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "\n",
    "def CostVanillaKmeanspp(Ktarget,dfValues):\n",
    "    #k-means++\n",
    "\n",
    "    seeds=[0,100,200,300,400,500,600,700,800,900]\n",
    "    cost = []\n",
    "    for seed in seeds:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        kmean_obj = KMeans(n_clusters=Ktarget, init='k-means++' ,random_state=seed).fit(dfValues)\n",
    "        \n",
    "        cost.append(kmean_obj.inertia_)    #Sum of squarred euc dis \n",
    "        \n",
    "    return np.mean(cost), np.std(cost)     #average over 10 runs  \n",
    " \n",
    "    \n",
    "def CostVanillaKmeansList(Ktarget,dfValues):\n",
    "    \n",
    "    \n",
    "    seeds=[0,100,200,300,400,500,600,700,800,900]\n",
    "    cost = []\n",
    "    for seed in seeds:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        kmean_obj = KMeans(n_clusters=Ktarget, init='random' ,random_state=seed).fit(dfValues)\n",
    "        \n",
    "        cost.append(kmean_obj.inertia_)    #Sum of squarred euc dis \n",
    "        \n",
    "        labels = kmean_obj.labels_ \n",
    "        \n",
    "        cluster_centers = kmean_obj.cluster_centers_\n",
    "        \n",
    "        cost_seed = []\n",
    "        for i in range(Ktarget):\n",
    "            cluster_data = dfValues[labels == i]\n",
    "            distances = distance.cdist(cluster_data, [cluster_centers[i]], 'euclidean')\n",
    "            cost_seed.append( np.sum(distances ** 2))\n",
    "        cost.append(np.max(cost_seed))\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    return cost#, np.std(cost)    #average over 10 runs     \n",
    "\n",
    "def CostVanillaKmeans(Ktarget,dfValues):\n",
    "    \n",
    "    \n",
    "    seeds=[0,100,200,300,400,500,600,700,800,900]\n",
    "    cost = []\n",
    "    for seed in seeds:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        kmean_obj = KMeans(n_clusters=Ktarget, init='random' ,random_state=seed).fit(dfValues)\n",
    "        \n",
    "        cost.append(kmean_obj.inertia_)    #Sum of squarred euc dis \n",
    "        \n",
    "    \n",
    "    \n",
    "    return np.mean(cost)#, np.std(cost)    #average over 10 runs     \n",
    "\n",
    "\n",
    "def CostVanillaKrandom(Ktarget,dfValues):\n",
    "    \n",
    "    seeds=[0,100,200,300,400,500,600,700,800,900]\n",
    "    cost = []\n",
    "    for seed in seeds:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        n_row, n_col = dfValues.shape\n",
    "        rand_indices = np.random.choice(n_row, size = Ktarget)\n",
    "        centroids = dfValues[rand_indices]\n",
    "        \n",
    "        distances_to_centroids = distance.cdist(dfValues, centroids, 'sqeuclidean')\n",
    "        cluster_assignment = np.argmin(distances_to_centroids, axis = 1)\n",
    "        heterogeneity=0\n",
    "        for i in range(Ktarget):\n",
    "            cluster_data = dfValues[cluster_assignment == i]\n",
    "            distances = distance.cdist(cluster_data, [centroids[i]], 'euclidean')\n",
    "            heterogeneity += np.sum(distances ** 2)\n",
    "        \n",
    "        cost.append(heterogeneity)\n",
    "    \n",
    "    return np.mean(cost)#, np.std(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
